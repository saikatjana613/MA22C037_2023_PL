{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = { \\\n",
    "'Lincoln1865':\n",
    "'With malice toward none, with charity for all ...' +\n",
    "'let us strive on to finish the work we are in ... ' +\n",
    "'to do all which may achieve and cherish a just and lasting peace, ' +\n",
    "'among ourselves, and with all nations.',\n",
    "\n",
    "'TrumpMay26':\n",
    "'There is NO WAY (ZERO!) that Mail-In Ballots ' +\n",
    "'will be anything less than substantially fraudulent.',\n",
    "\n",
    "'Wikipedia':\n",
    "'In 1998, Oregon became the first state in the US ' +\n",
    "'to conduct all voting exclusively by mail.',\n",
    "\n",
    "'FortuneMay26':\n",
    "'Over the last two decades, about 0.00006% of total ' +\n",
    "'vote-by-mail votes cast were fraudulent.',\n",
    "\n",
    "'TheHillApr07':\n",
    "'Trump voted by mail in the Florida primary.',\n",
    "\n",
    "'KingJamesBible':\n",
    "'Wherefore laying aside all malice, and all guile, and ' +\n",
    "'hypocrisies, and envies, and all evil speakings',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                00006  1998  about  achieve  all  among  and  anything  are  \\\n",
      "Lincoln1865         0     0      0        1    3      1    3         0    1   \n",
      "TrumpMay26          0     0      0        0    0      0    0         1    0   \n",
      "Wikipedia           0     1      0        0    1      0    0         0    0   \n",
      "FortuneMay26        1     0      1        0    0      0    0         0    0   \n",
      "TheHillApr07        0     0      0        0    0      0    0         0    0   \n",
      "KingJamesBible      0     0      0        0    3      0    4         0    0   \n",
      "\n",
      "                aside  ...  voting  way  we  were  wherefore  which  will  \\\n",
      "Lincoln1865         0  ...       0    0   1     0          0      1     0   \n",
      "TrumpMay26          0  ...       0    1   0     0          0      0     1   \n",
      "Wikipedia           0  ...       1    0   0     0          0      0     0   \n",
      "FortuneMay26        0  ...       0    0   0     1          0      0     0   \n",
      "TheHillApr07        0  ...       0    0   0     0          0      0     0   \n",
      "KingJamesBible      1  ...       0    0   0     0          1      0     0   \n",
      "\n",
      "                with  work  zero  \n",
      "Lincoln1865        3     1     0  \n",
      "TrumpMay26         0     0     1  \n",
      "Wikipedia          0     0     0  \n",
      "FortuneMay26       0     0     0  \n",
      "TheHillApr07       0     0     0  \n",
      "KingJamesBible     0     0     0  \n",
      "\n",
      "[6 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of document keys\n",
    "document_keys = list(c.keys())\n",
    "\n",
    "# Create a CountVectorizer instance\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus using CountVectorizer\n",
    "X = vectorizer.fit_transform(c.values())\n",
    "\n",
    "# Convert the result to a data frame\n",
    "term_document_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=document_keys)\n",
    "\n",
    "# Display the term-document matrix\n",
    "print(term_document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a custom tokenizer function\n",
    "def custom_tokenizer(text):\n",
    "    tokens = nlp(text)\n",
    "    return [token.lemma_ for token in tokens if not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0.00006  1998  a  about  achieve  all  among  and  anything  \\\n",
      "Lincoln1865           0     0  1      0        1    3      1    3         0   \n",
      "TrumpMay26            0     0  0      0        0    0      0    0         1   \n",
      "Wikipedia             0     1  0      0        0    1      0    0         0   \n",
      "FortuneMay26          1     0  0      1        0    0      0    0         0   \n",
      "TheHillApr07          0     0  0      0        0    0      0    0         0   \n",
      "KingJamesBible        0     0  0      0        0    3      0    4         0   \n",
      "\n",
      "                aside  ...  vote  voting  way  we  wherefore  which  will  \\\n",
      "Lincoln1865         0  ...     0       0    0   2          0      1     0   \n",
      "TrumpMay26          0  ...     0       0    1   0          0      0     1   \n",
      "Wikipedia           0  ...     0       1    0   0          0      0     0   \n",
      "FortuneMay26        0  ...     2       0    0   0          0      0     0   \n",
      "TheHillApr07        0  ...     1       0    0   0          0      0     0   \n",
      "KingJamesBible      1  ...     0       0    0   0          1      0     0   \n",
      "\n",
      "                with  work  zero  \n",
      "Lincoln1865        3     1     0  \n",
      "TrumpMay26         0     0     1  \n",
      "Wikipedia          0     0     0  \n",
      "FortuneMay26       0     0     0  \n",
      "TheHillApr07       0     0     0  \n",
      "KingJamesBible     0     0     0  \n",
      "\n",
      "[6 rows x 74 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rajarshi\\miniconda3\\envs\\iitm_PL\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer instance with the custom tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "\n",
    "# Fit and transform the corpus using CountVectorizer\n",
    "X = vectorizer.fit_transform(c.values())\n",
    "\n",
    "# Convert the result to a data frame with clear labeling\n",
    "term_document_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
    "\n",
    "# Display the term-document matrix\n",
    "print(term_document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA representations of documents:\n",
      "                   LSA_1     LSA_2     LSA_3\n",
      "Lincoln1865     7.386029  0.089226 -2.288112\n",
      "TrumpMay26      0.520975  2.218354  0.487372\n",
      "Wikipedia       1.578395  2.968300  0.739028\n",
      "FortuneMay26    0.445616  2.771292  1.199554\n",
      "TheHillApr07    0.412929  1.751775  0.544510\n",
      "KingJamesBible  4.116111 -2.054894  3.576262\n",
      "\n",
      "LSA representation of the word 'vote':\n",
      "[0.01747558 0.25405951 0.14328202]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Define the number of dimensions for the LSA representation\n",
    "n_components = 3\n",
    "\n",
    "# Perform LSA on the term-document matrix\n",
    "lsa = TruncatedSVD(n_components)\n",
    "lsa_result = lsa.fit_transform(term_document_matrix)\n",
    "\n",
    "# Create a DataFrame for the LSA representation\n",
    "lsa_df = pd.DataFrame(lsa_result, columns=[f'LSA_{i+1}' for i in range(n_components)], index=c.keys())\n",
    "\n",
    "# Print the LSA representations of documents\n",
    "print(\"LSA representations of documents:\")\n",
    "print(lsa_df)\n",
    "\n",
    "# Find the LSA representation of the word 'vote'\n",
    "word_index = term_document_matrix.columns.get_loc('vote')\n",
    "word_representation = lsa.components_[:, word_index]\n",
    "print(\"\\nLSA representation of the word 'vote':\")\n",
    "print(word_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'malice' and 'vote': 0.3844065678276618\n",
      "Cosine similarity between 'mail' and 'vote': 0.9683590759737168\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define a function to compute cosine similarity\n",
    "def compute_cosine_similarity(vector1, vector2):\n",
    "    # Reshape the vectors to be 2D arrays (required for cosine_similarity)\n",
    "    vector1 = vector1.reshape(1, -1)\n",
    "    vector2 = vector2.reshape(1, -1)\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    similarity = cosine_similarity(vector1, vector2)\n",
    "    \n",
    "    return similarity[0][0]\n",
    "\n",
    "# Compute cosine similarity between 'malice' and 'vote'\n",
    "cosine_malice_vote = compute_cosine_similarity(\n",
    "    lsa_df.loc['Lincoln1865'].to_numpy(),\n",
    "    lsa_df.loc['Wikipedia'].to_numpy()\n",
    ")\n",
    "\n",
    "# Compute cosine similarity between 'mail' and 'vote'\n",
    "cosine_mail_vote = compute_cosine_similarity(\n",
    "    lsa_df.loc['TrumpMay26'].to_numpy(),\n",
    "    lsa_df.loc['Wikipedia'].to_numpy()\n",
    ")\n",
    "\n",
    "print(f\"Cosine similarity between 'malice' and 'vote': {cosine_malice_vote}\")\n",
    "print(f\"Cosine similarity between 'mail' and 'vote': {cosine_mail_vote}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  00006      1998    about   achieve       all     among  \\\n",
      "Lincoln1865     0.00000  0.000000  0.00000  0.147276  0.305882  0.147276   \n",
      "TrumpMay26      0.00000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
      "Wikipedia       0.00000  0.272458  0.00000  0.000000  0.188626  0.000000   \n",
      "FortuneMay26    0.26865  0.000000  0.26865  0.000000  0.000000  0.000000   \n",
      "TheHillApr07    0.00000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
      "KingJamesBible  0.00000  0.000000  0.00000  0.000000  0.426225  0.000000   \n",
      "\n",
      "                     and  anything       are     aside  ...    voting  \\\n",
      "Lincoln1865     0.362304   0.00000  0.147276  0.000000  ...  0.000000   \n",
      "TrumpMay26      0.000000   0.26374  0.000000  0.000000  ...  0.000000   \n",
      "Wikipedia       0.000000   0.00000  0.000000  0.000000  ...  0.272458   \n",
      "FortuneMay26    0.000000   0.00000  0.000000  0.000000  ...  0.000000   \n",
      "TheHillApr07    0.000000   0.00000  0.000000  0.000000  ...  0.000000   \n",
      "KingJamesBible  0.673126   0.00000  0.000000  0.205218  ...  0.000000   \n",
      "\n",
      "                    way        we     were  wherefore     which     will  \\\n",
      "Lincoln1865     0.00000  0.147276  0.00000   0.000000  0.147276  0.00000   \n",
      "TrumpMay26      0.26374  0.000000  0.00000   0.000000  0.000000  0.26374   \n",
      "Wikipedia       0.00000  0.000000  0.00000   0.000000  0.000000  0.00000   \n",
      "FortuneMay26    0.00000  0.000000  0.26865   0.000000  0.000000  0.00000   \n",
      "TheHillApr07    0.00000  0.000000  0.00000   0.000000  0.000000  0.00000   \n",
      "KingJamesBible  0.00000  0.000000  0.00000   0.205218  0.000000  0.00000   \n",
      "\n",
      "                    with      work     zero  \n",
      "Lincoln1865     0.441827  0.147276  0.00000  \n",
      "TrumpMay26      0.000000  0.000000  0.26374  \n",
      "Wikipedia       0.000000  0.000000  0.00000  \n",
      "FortuneMay26    0.000000  0.000000  0.00000  \n",
      "TheHillApr07    0.000000  0.000000  0.00000  \n",
      "KingJamesBible  0.000000  0.000000  0.00000  \n",
      "\n",
      "[6 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the corpus using TfidfVectorizer\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(c.values())\n",
    "\n",
    "# Convert the result to a data frame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=c.keys())\n",
    "\n",
    "# Display the TF-IDF matrix\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'malice' and 'vote' (TF-IDF): 0.19513415920023014\n",
      "Cosine similarity between 'mail' and 'vote' (TF-IDF): 0.0758726657016838\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between 'malice' and 'vote' using TF-IDF matrix\n",
    "cosine_malice_vote_tfidf = compute_cosine_similarity(\n",
    "    tfidf_df.loc['Lincoln1865'].to_numpy(),\n",
    "    tfidf_df.loc['Wikipedia'].to_numpy()\n",
    ")\n",
    "\n",
    "# Compute cosine similarity between 'mail' and 'vote' using TF-IDF matrix\n",
    "cosine_mail_vote_tfidf = compute_cosine_similarity(\n",
    "    tfidf_df.loc['TrumpMay26'].to_numpy(),\n",
    "    tfidf_df.loc['Wikipedia'].to_numpy()\n",
    ")\n",
    "\n",
    "print(f\"Cosine similarity between 'malice' and 'vote' (TF-IDF): {cosine_malice_vote_tfidf}\")\n",
    "print(f\"Cosine similarity between 'mail' and 'vote' (TF-IDF): {cosine_mail_vote_tfidf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitm_PL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
